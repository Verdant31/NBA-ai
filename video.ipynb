{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO, trackers\n",
    "import cv2\n",
    "import os\n",
    "import supervision as sv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics.data.annotator import auto_annotate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/jpeg;base64,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\" />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "\n",
    "def convert_to_base64(pil_image):\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"JPEG\")  \n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return img_str\n",
    "\n",
    "\n",
    "def plt_img_base64(img_base64):\n",
    "    image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "    display(HTML(image_html))\n",
    "\n",
    "\n",
    "file_path = \"./cropped/magicVShawks.mp4--405d13a9-78fb-43a6-862d-c708e8d787ad.jpg\"\n",
    "pil_image = Image.open(file_path)\n",
    "\n",
    "image_b64 = convert_to_base64(pil_image)\n",
    "plt_img_base64(image_b64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOllama(model=\"llava-llama3\", temperature=0)\n",
    "\n",
    "def prompt_func(data):\n",
    "    text = data[\"text\"]\n",
    "    image = data[\"image\"]\n",
    "\n",
    "    image_part = {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": f\"data:image/jpeg;base64,{image}\",\n",
    "    }\n",
    "\n",
    "    content_parts = []\n",
    "\n",
    "    text_part = {\"type\": \"text\", \"text\": text}\n",
    "\n",
    "    content_parts.append(image_part)\n",
    "    content_parts.append(text_part)\n",
    "\n",
    "    return [HumanMessage(content=content_parts)]\n",
    "\n",
    "\n",
    "chain = prompt_func | llm | StrOutputParser()\n",
    "\n",
    "query_chain = chain.invoke(\n",
    "    {\"text\": \"Examine the provided image of a basketball player and extract the jersey number. If the jersey number is clearly visible and unambiguous, output only the numeric digits corresponding to the jersey number, with no additional text or explanation. If the jersey number is not clearly identifiable (e.g., due to blurriness or other quality issues), do not guess or generate a number; instead, output nothing\", \"image\": image_b64}\n",
    ")\n",
    "\n",
    "print(query_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "image_path = \"./cropped/magicVShawks.mp4--0c95c3b1-9820-4782-949e-a58960573f92.jpg\"\n",
    "\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format={\"type\": \"json_object\"},  \n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Analyze the basketball player's jersey in the image. Extract ONLY the numerical jersey number. Return JSON: { 'jerseyNumber': number | 'undefined' }. IT IS CRUCIAL TO RETURN 'undefined' IF NO NUMBER IS VISIBLE.\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"},\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_data = json.loads(response.choices[0].message.content)\n",
    "print(json_data['jerseyNumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from utils import log\n",
    "from tqdm import tqdm  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.system('cls' if os.name == 'nt' else 'clear')\n",
    "    frames = []\n",
    "    cropped_dir = \"./cropped\"\n",
    "    \n",
    "    for img_file in os.listdir(cropped_dir):\n",
    "        frame = cv2.imread(os.path.join(cropped_dir, img_file))\n",
    "        frames.append({\n",
    "            \"frame\": frame,\n",
    "            \"file_name\": img_file\n",
    "        })\n",
    "\n",
    "    try:\n",
    "        for index, frame_data in enumerate(frames):\n",
    "            cv2.imshow(\"Frame\", frame_data[\"frame\"])\n",
    "            key = cv2.waitKey(0) & 0xFF  # Wait for a key press\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            if key == ord('y') or key == ord('Y'):\n",
    "                file_path = os.path.join(cropped_dir, frame_data[\"file_name\"])\n",
    "                try:\n",
    "                    os.remove(file_path)\n",
    "                    log(f\"Deleted: {frame_data['file_name']}\")\n",
    "                except Exception as e:\n",
    "                    log(f\"Error deleting {frame_data['file_name']}: {e}\")\n",
    "                \n",
    "                \n",
    "    except Exception as e:\n",
    "        log(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "import uuid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "model_path = os.path.join('runs/detect/train16/weights', 'best.pt')\n",
    "model = YOLO(model_path, verbose=False)\n",
    "\n",
    "input_video_path = './test/big_input.mp4'\n",
    "output_video_path = './test/output.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "frame_interval = int(fps * 0.1)\n",
    "\n",
    "frame_count = 0\n",
    "saved_frame_count = 0\n",
    "\n",
    "out = cv2.VideoWriter(\n",
    "    output_video_path,\n",
    "    cv2.VideoWriter_fourcc(*'MP4V'),\n",
    "    fps,\n",
    "    (frame_width, frame_height)\n",
    ")\n",
    "\n",
    "frames = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if frame_count % frame_interval == 0:\n",
    "        original_frame = frame.copy()\n",
    "        results = model.predict(frame, device=device, verbose=False)\n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                conf = box.conf[0].item()\n",
    "                cls = int(box.cls[0].item())\n",
    "                \n",
    "                label = f\"{model.names[cls]} {conf:.2f}\"\n",
    "                \n",
    "                croped = original_frame[y1:y2, x1:x2]\n",
    "                results = reader.readtext(croped, detail=0)\n",
    "                if(model.names[cls] == \"player\"):\n",
    "                    cv2.imwrite(f'./cropped/{uuid.uuid4()}.png', croped)\n",
    "            \n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        frames.append(original_frame)\n",
    "    frame_count += 1\n",
    "\n",
    " \n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread(\"./test.png\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Optional: Apply adaptive thresholding to enhance contrast\n",
    "thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                               cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Visualize the preprocessed image\n",
    "plt.imshow(thresh, cmap='gray')\n",
    "plt.title(\"Preprocessed Image for EasyOCR\")\n",
    "plt.show()\n",
    "\n",
    "# Initialize EasyOCR reader (for English)\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Perform OCR on the preprocessed image\n",
    "results = reader.readtext(thresh, detail=1, paragraph=False)\n",
    "\n",
    "# Extract only the text portions that contain digits\n",
    "detected_numbers = [text for bbox, text, conf in results if text.isdigit()]\n",
    "\n",
    "print(\"Detected jersey number(s) (EasyOCR):\", detected_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB4, preprocess_input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model = EfficientNetB4(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "\n",
    "def extract_features(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    features = model.predict(img_array, verbose=0)\n",
    "    return features.flatten()\n",
    "\n",
    "folder_path = './cropped'\n",
    "features_list = []\n",
    "img_paths = []\n",
    "\n",
    "for img_file in os.listdir(folder_path):\n",
    "    if img_file.endswith(('.jpg', '.png')):\n",
    "        img_path = os.path.join(folder_path, img_file)\n",
    "        img_paths.append(img_path)\n",
    "        features = extract_features(img_path)\n",
    "        features_list.append(features)\n",
    "\n",
    "features_array = np.array(features_list)\n",
    "\n",
    "# import umap\n",
    "# reducer = umap.UMAP(n_components=50, random_state=42)\n",
    "# features_reduced = reducer.fit_transform(features_scaled)\n",
    "\n",
    "# import hdbscan\n",
    "# clusterer = hdbscan.HDBSCAN(min_cluster_size=10, gen_min_span_tree=True)\n",
    "# clusters = clusterer.fit_predict(features_scaled)\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "clustering = SpectralClustering(n_clusters=10, affinity='nearest_neighbors', n_neighbors=10)\n",
    "clusters = clustering.fit_predict(features_array)\n",
    "\n",
    "k = 10  \n",
    "# kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "# clusters = kmeans.fit_predict(features_array)\n",
    "\n",
    "\n",
    "\n",
    "score = silhouette_score(features_array, clusters)\n",
    "print(f\"Silhouette Score: {score:.2f}\")\n",
    "\n",
    "output_folder = './kmeans'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "for cluster_num in range(k):\n",
    "    cluster_folder = os.path.join(output_folder, f'cluster_{cluster_num}')\n",
    "    if not os.path.exists(cluster_folder):\n",
    "        os.makedirs(cluster_folder)\n",
    "\n",
    "    idxs = [i for i, label in enumerate(clusters) if label == cluster_num]\n",
    "    for i, idx in enumerate(idxs):\n",
    "        img = cv2.imread(img_paths[idx])\n",
    "        img_name = os.path.basename(img_paths[idx])\n",
    "        save_path = os.path.join(cluster_folder, img_name)\n",
    "        cv2.imwrite(save_path, img)\n",
    "\n",
    "print(f\"Imagens salvas em {output_folder}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basket-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
