{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO, trackers\n",
    "import cv2\n",
    "import os\n",
    "import supervision as sv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics.data.annotator import auto_annotate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "model_path = os.path.join('runs/detect/train12/weights', 'best.pt')\n",
    "model = YOLO(model_path, verbose=False)\n",
    "\n",
    "input_video_path = './test/small_input.mp4'\n",
    "output_video_path = './test/output.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "out = cv2.VideoWriter(\n",
    "    output_video_path,\n",
    "    cv2.VideoWriter_fourcc(*'MP4V'),\n",
    "    fps,\n",
    "    (frame_width, frame_height)\n",
    ")\n",
    "\n",
    "frames = []\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    original_frame = frame.copy()\n",
    "    \n",
    "    results = model.predict(frame, device=device, verbose=False)\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            conf = box.conf[0].item()\n",
    "            cls = int(box.cls[0].item())\n",
    "            \n",
    "            label = f\"{model.names[cls]} {conf:.2f}\"\n",
    "            \n",
    "            croped = original_frame[y1:y2, x1:x2]\n",
    "            results = reader.readtext(croped, detail=0)\n",
    "            # plot croped frame with identified text as label\n",
    "            plt.figure()\n",
    "            plt.title(f'Text: {''.join(results)}')\n",
    "            plt.imshow(croped)\n",
    "            plt.show()\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    frames.append(original_frame)\n",
    "\n",
    " \n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import pytesseract\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import easyocr\n",
    "import supervision as sv\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Carregar a imagem\n",
    "image = cv2.imread('./image.png')\n",
    "\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    ")\n",
    "\n",
    "result = CLIENT.infer(image, model_id=\"chequemodel/1\")\n",
    "\n",
    "detections = sv.Detections.from_inference(result)\n",
    "\n",
    "annotated_image = sv.BoundingBoxAnnotator().annotate(image.copy(),detections)\n",
    "annotated_image = sv.LabelAnnotator(text_scale=0.3).annotate(annotated_image,detections)\n",
    "\n",
    "sv.plot_image(annotated_image, (6,6))\n",
    "class_list = detections.data[\"class_name\"]\n",
    "name_detection = detections[class_list == \"Payee_Name\"]\n",
    "name_image = sv.crop_image(image,name_detection.xyxy[0].tolist())\n",
    "\n",
    "amount_detection = detections[class_list == \"Amount_In_Numbers\"]\n",
    "amount_image = sv.crop_image(image,amount_detection.xyxy[0].tolist())\n",
    "\n",
    "sv.plot_image(name_image,(4,4))\n",
    "sv.plot_image(amount_image,(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "psm = 6\n",
    "config = '--oem 3 --psm %d' % psm\n",
    "\n",
    "\n",
    "image = frames[0]\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "data = pytesseract.image_to_string(thresh, lang='eng', config=config)\n",
    "print(data)\n",
    "# Loop through detected text and draw bounding boxes\n",
    "for i in range(len(data)):\n",
    "    x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
    "    text = data['text'][i]\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    cv2.putText(image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Detected Text', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basket-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
